# [Semantic Vectors](https://github.com/BarbaraPFloresRios/IDS703_NLP_NaturalLanguageProcessing/tree/main/202311_SemanticVectors)
### BÃ¡rbara Flores

**Semantic Vectors:**

Semantic vectors" are numerical representations that capture the meaning of words, phrases, or documents in a vector space. These vectors are used in natural language processing to understand and measure semantic similarity between words or texts, which is crucial in tasks such as information retrieval, text classification, and machine translation.

**Assigment:**

In this context, the task is to modify and enhance the provided [input_document_vectors_experiment.py](https://github.com/BarbaraPFloresRios/IDS703_NLP_NaturalLanguageProcessing/blob/main/20231101_SemanticVectors/input_document_vectors_experiment.py), which was given in the Introduction to NLP class, taught by Patrick Wang, to explore how dense word/document embeddings can be used for document classification. The task is to to distinguish between documents from two different authors. We will implement two types of dense document vectors:

- Using Latent Semantic Analysis (LSA) on raw token counts.
- Summing pretrained Word2Vec embeddings.
Both methods will produce document vectors of length 300. The results and discussion of this new task will be included in the same repository.

For more details about the exercise, you can refer to the [assignment_instructions.pdf](https://github.com/BarbaraPFloresRios/IDS703_NLP_NaturalLanguageProcessing/blob/main/20231101_SemanticVectors/%20assignment_instructions.pdf) file.

You can find my completed work for this project in [document_vectors_experiment.py](https://github.com/BarbaraPFloresRios/IDS703_NLP_NaturalLanguageProcessing/blob/main/20231101_SemanticVectors/document_vectors_experiment.py) file
